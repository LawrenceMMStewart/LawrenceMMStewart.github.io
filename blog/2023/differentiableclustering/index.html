<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Differentiable Clustering | Lawrence Stewart</title> <meta name="author" content="Lawrence Stewart"> <meta name="description" content="A step-by-step guide to Differentiable Clustering for Deep Learning."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/lsinitial.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lawrencemmstewart.github.io/blog/2023/differentiableclustering/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Differentiable Clustering",
      "description": "A step-by-step guide to Differentiable Clustering for Deep Learning.",
      "published": "November 29, 2023",
      "authors": [
        {
          "author": "Lawrence Stewart",
          "authorURL": "https://lawrencemmstewart.github.io/",
          "affiliations": [
            {
              "name": "Ecole Normale Superieure, INRIA Paris",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Lawrence </span>Stewart</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Differentiable Clustering</h1> <p>A step-by-step guide to Differentiable Clustering for Deep Learning.</p> </d-title> <d-byline></d-byline> <d-article> <h2 id="clustering">Clustering</h2> <p>Clustering is one of the most classical and commonplace tasks in Machine Learning. The goal is to separate data \(x_1, \ldots, x_n\) into \(k\) groups, which are refered to as clusters. Clustering has wide-spread applications in bio-informatics, data compression, graphics, unsupervised and semi-supervised learning, as well as many other domains!</p> <p>There is a large collection of <a href="https://en.wikipedia.org/wiki/Cluster_analysis" rel="external nofollow noopener" target="_blank">well established clustering algorithms</a> (with a select few being displayed in the table below).</p> <table> <thead> <tr> <th>Methodology</th> <th>Examples</th> <th>Possible Drawbacks</th> </tr> </thead> <tbody> <tr> <td>centroid</td> <td>k-means</td> <td>NP-Hard, heuristic (not direct solve of objective function).</td> </tr> <tr> <td>connectivity</td> <td>Linkage Algorithms (e.g. Single, UPGMA)</td> <td>Computational Costly, Outliers.</td> </tr> <tr> <td>distribution</td> <td>EM Gaussian</td> <td>Overfitting, Assumptions.</td> </tr> </tbody> </table> <p>When dealing with semantic data e.g. Images or Text, applying such algorithms to the data directly is unlikely to lead to meaningful clusters.<d-footnote> To see this, try applying k-means directly on the MNIST data set </d-footnote>! Instead, we would like to learn representations of are data e.g. features of a Neural Network, which when clustered, lead to clusters which capture meaningful semantic information.</p> <p>Unfortunately, we cannot just plug any classical clustering algorithm into a Deep Learning pipeline<d-footnote> Or more generally, gradient based learning pipeline.</d-footnote> <img class="emoji" title=":dizzy_face:" alt=":dizzy_face:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f635.png" height="20" width="20"> .</p> <p>Why not? The answer is in the box below:</p> <details><summary><img class="emoji" title=":warning:" alt=":warning:" src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png" height="20" width="20"> Gradient Based Learning Compatibility with Classical Clustering?</summary> <p>As a function, the solution of a clustering problem is piece-wise constant with respect to its inputs (such as a similarity or distance matrix), and its <strong>gradient would therefore be zero almost everywhere</strong>. This operation is therefore naturally ill-suited to the use of gradient-based approaches to minimize an objective, such as backpropagation for training Neural Networks.</p> <p>If the above is not clear at first, just not that the cluster assignment of \(x_i\) will almost always be the same as the cluster assignment for \(x_i + \epsilon\) where \(\epsilon\) denotes an infinitesimal change, so the gradient will be zero.</p> </details> <h2 id="goal-rocket">Goal <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> </h2> <p>In this blog post we will give a simple explanation of our recent work that aims to address the above problem. We will keep math and other technical details to an absolute minimum, but for a more complete picture you can refer to the paper <d-cite key="stewart2023differentiable"></d-cite>.</p> <p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> For any further questions, please feel free to contact me !</p> <h2 id="kruskals-algorithm">Kruskal’s Algorithm</h2> <h4 id="viewing-our-data-as-a-graph">Viewing our data as a graph</h4> <p>Firstly, we will recap maximum weight spanning forests and kruskals algorithm.</p> <p>We can think of our data \(x_1, \ldots, x_n \in \mathbb{R}^d\) as nodes of a fully-connected graph \(K_n\), where the weight of an edge \((i,j)\) is given by the \((i,j)^{th}\) entry of a user-chosen similarity matrix \(\Sigma \in \mathbb{R}^{n\times n}\). A large value of \(\Sigma_{i,j}\) means that points \(i\) and \(j\) are similar, whilst a smaller value means that the points are disimilar.</p> <p>Below is an example graph for two different typical choices of \(\Sigma\).</p> <figure> <picture> <img src="/assets/img/blog-differentiableclustering/Kn.svg" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <details><summary>Code for Figure</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Generate random nodes
</span><span class="n">N</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Calculate pairwise distances
</span><span class="n">distances</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">nodes</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="n">nodes</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="nf">get_cmap</span><span class="p">(</span><span class="sh">'</span><span class="s">plasma</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># Create a graph with nodes and edges
</span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="p">.</span><span class="nf">add_nodes_from</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>

<span class="c1"># Extract edge weights
</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="sh">'</span><span class="s">weight</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="nf">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span>
<span class="n">exp_edge_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edge_weights</span><span class="p">]</span>

<span class="c1"># Create a graph plot
</span><span class="n">pos</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">))</span>  <span class="c1"># Use the node positions as given by their coordinates
</span><span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Draw edges with colors based on weights
</span><span class="n">edges</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">edge_weights</span><span class="p">,</span> <span class="n">edge_cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">edge_vmin</span><span class="o">=</span><span class="nf">min</span><span class="p">(</span><span class="n">edge_weights</span><span class="p">),</span> <span class="n">edge_vmax</span><span class="o">=</span><span class="nf">max</span><span class="p">(</span><span class="n">edge_weights</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">exp_edges</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">exp_edge_weights</span><span class="p">,</span> <span class="n">edge_cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">edge_vmin</span><span class="o">=</span><span class="nf">min</span><span class="p">(</span><span class="n">exp_edge_weights</span><span class="p">),</span> <span class="n">edge_vmax</span><span class="o">=</span><span class="nf">max</span><span class="p">(</span><span class="n">exp_edge_weights</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\Sigma_{ij} = - |\|x_i - x_j|\|_2^2$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\Sigma_{ij} = \exp\left( - |\|x_i - x_j|\|_2^2\right)$</span><span class="sh">'</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">exp_edges</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">Kn.pdf</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> </details> <h3 id="spanning-trees">Spanning trees</h3> <p>For the complete graph \(K_n\) over nodes \(\{x_1, \ldots, x_n\}\), we denote by \(\mathcal{T}_n\) the set of <em>spanning trees</em> on \(K_n\), i.e., subgraphs with no cycles and one connected component. Among these trees will be one or more that has maximum weight (the total weight of all edges in the tree), which is known as the <em>maximum weight spanning tree</em>.</p> <p><code class="language-plaintext highlighter-rouge">Kruskals algorithm</code> is a greedy algorithm to find a maximum weight spanning tree. It is incredibly simple, and consists of adding edges in a greedy manner to build the tree, and ignoring an edge if it would lead to a cycle. The psuedo-code for the algorithm is as follows:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># 
</span><span class="n">tree</span> <span class="o">=</span> <span class="p">{}</span> 
<span class="n">edges</span> <span class="o">=</span> <span class="nf">sort</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
  <span class="k">if</span> <span class="nf">union</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="p">{</span><span class="n">e</span><span class="p">})</span> <span class="n">has</span> <span class="n">no</span> <span class="n">cycle</span><span class="p">:</span>
    <span class="n">tree</span> <span class="o">=</span> <span class="nf">union</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="p">{</span><span class="n">e</span><span class="p">})</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">pass</span>
  <span class="k">if</span> <span class="n">tree</span> <span class="ow">is</span> <span class="n">spanning</span><span class="p">:</span>
    <span class="k">break</span></code></pre></figure> <p>At each time step $t$, we will have a forest with $k=n-t$ connected components, where $n$ is the number of data points / nodes in the graph. A visual depiction of the algorithm in action can be seen below:</p> <figure> <picture> <img src="/assets/img/blog-differentiableclustering/mst.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <details><summary>Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">jaxclust</span>
<span class="kn">import</span> <span class="n">jax</span>
<span class="kn">import</span> <span class="n">jax.numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="n">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="nd">@jax.jit</span>
<span class="k">def</span> <span class="nf">pairwise_square_distance</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    euclidean pairwise square distance between data points
    </span><span class="sh">"""</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">G</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">o</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">g</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">G</span>

<span class="n">NODE_COLOR</span><span class="o">=</span><span class="sh">'</span><span class="s">#1b9e77</span><span class="sh">'</span>
<span class="n">EDGE_COLOR</span><span class="o">=</span><span class="sh">'</span><span class="s">#7570b3</span><span class="sh">'</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="nf">jit</span><span class="p">(</span><span class="n">jaxclust</span><span class="p">.</span><span class="n">solvers</span><span class="p">.</span><span class="nf">get_flp_solver</span><span class="p">(</span><span class="bp">False</span><span class="p">))</span>

<span class="n">N_SAMPLES</span><span class="o">=</span><span class="mi">32</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">centers</span> <span class="o">=</span> <span class="nf">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_SAMPLES</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">return_centers</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span>

<span class="n">S</span> <span class="o">=</span> <span class="o">-</span> <span class="nf">pairwise_square_distance</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="n">writer</span> <span class="o">=</span> <span class="nc">PillowWriter</span><span class="p">(</span><span class="n">fps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">artist</span><span class="o">=</span><span class="sh">'</span><span class="s">Me</span><span class="sh">'</span><span class="p">),</span> <span class="n">bitrate</span><span class="o">=</span><span class="mi">1800</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="sh">'</span><span class="s">constrained</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">node_positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)}</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="p">.</span><span class="nf">add_nodes_from</span><span class="p">(</span><span class="n">node_positions</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">node_positions</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">NODE_COLOR</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">EDGE_COLOR</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># Function to update the animation
</span><span class="k">def</span> <span class="nf">update_forest</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">clear</span><span class="p">()</span>

        <span class="n">A</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="nf">solver</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">ncc</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>

        <span class="n">node_positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)}</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_nodes_from</span><span class="p">(</span><span class="n">node_positions</span><span class="p">)</span>

        <span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N_SAMPLES</span><span class="p">)</span> <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

        <span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">node_positions</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">NODE_COLOR</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">EDGE_COLOR</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">rf</span><span class="sh">"</span><span class="s">$k = </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">$,   time step: </span><span class="si">{</span><span class="n">N_SAMPLES</span> <span class="o">-</span> <span class="n">step</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>




<span class="n">frames</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">reversed</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_SAMPLES</span><span class="p">)))</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">frames</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">30</span>
<span class="n">animation</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update_forest</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">frames</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>

<span class="n">animation</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">mst.gif</span><span class="sh">'</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> </details> <h3 id="obtaining-spanning-forests-early-stopping">Obtaining Spanning Forests (early stopping)</h3> <p>When running Kruskal’s algorithm, one typically builds the tree \(T\) by keeping track of the adjacency matrix \(A\in \{0, 1\}^{n\times n}\) of the forest at each time step. We recall that:</p> \[\begin{equation*} A_{i,j} = 1 \Longleftrightarrow (i,j)\in T \end{equation*}\] <p>If we are to stop Kruskal’s algorithm one step before completion, we will obtain a forest with \(k=2\) connected components. We can view these two connected components as clusters!</p> <p>More generally, if we are stop the algorithm \(k+1\) steps before completion, we will obtain a forest with \(k\) connected components. Whats nice, is it turns out that Kruskal’s algorithm has a <strong>Matroid Structure</strong>, when means that if we stop the algorithm when the forest has \(k\) connected components, that forest will indeed have maximum weight amongst all forests of \(K_n\) that have \(k\) connected components! More details are given in the box below, but they are not neccessary to understand the goal of this blog.</p> <details><summary>Optimality of Kruskal’s</summary> <p>The greedy optimality of Kruskal’s follows from the fact that the forests of \(\mathcal{G}\) correspond to independent sets of the <a href="https://en.wikipedia.org/wiki/Graphic_matroid" rel="external nofollow noopener" target="_blank">Graphic Matroid</a>.</p> <p>To verify this is true, note that the intersection of two forests is always a forest, and the spanning trees of a graph form the basis for the matroid. The matroid circuits can are the cycles in the graph. Optimality of Kruskal’s follows trivially (as the algorithm is equivalent to finding the maximum weight basis of the graph matroid).</p> </details> <h3 id="from-adjacency-matrices-to-cluster-information">From Adjacency Matrices to Cluster Information</h3> <p>We will now relate the process of construct a \(k\)-spanning forest to clustering.</p> <p>Let \(\mathcal{A}\) denote the set of all adjacency matrices corresponding to forests of \(K_n\):</p> \[\begin{equation} \mathcal{A}=\{ A \subset \{0,1\}^{n\times n} : A \text{ is a forest of } K_n\}, \end{equation}\] <p>and let \(\mathcal{A}_k \subset \mathcal{A}\) denote such adjacency matrices that have \(k\) connected components. To relate an adjacency matrix $A\in \mathcal{A}$ to clustering, we define the cluster equivalence function:</p> \[\begin{equation} M : \mathcal{A} \rightarrow \{0,1\}^{n \times n} \end{equation}\] \[M(A)_{i,j} = \begin{cases} 1 \quad &amp;\text{if} \quad (i, j) \text{ are in the same connected component.} \\ 0 \quad &amp;\text{if} \quad (i, j) \text{ are in different connected components.} \\ \end{cases}\] <p>One can view the connected components of a forest as clusters, with two points \(x_i\) and \(x_j\) being in the same cluster if and only if \(M(A)_{ij} = 1\). For short hand, when talking about a fixed \(A_k\in \mathcal{A}_k\), we write \(M_k := M(A_k)\).</p> <details><summary>Relationship between \(A_k\) and \(M_k\)</summary> <p>You might have noticed that two different adjacency matrices (i.e. members of \(\mathcal{A}_k\)) may correspond to the same \(M_k\). Indeed, relabelling points from the same connected component changes \(A_k\), but will leave the corresponding \(M_k\) unchanged.</p> <p>Clearly the cluster equivalence mapping \(M\) is not injective. It turns out that \(M\) is an <strong>equivalence relation</strong>, and the <strong>equivalence classes</strong> of \(M\) are the sets of adjacency matricies mapping to the same cluster equivalence matrix (hence the <strong>equivalence</strong> being features in its name)!</p> </details> <h3 id="clustering-with-spanning-forests-aka-single-linkage">Clustering with Spanning Forests (aka Single Linkage)</h3> <p>We can hence obtain a clustering by running Kruskal’s to construct the maximum weight \(k\)-spanning forest:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span><span class="n">Sigma</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">do</span><span class="p">:</span>
    <span class="n">run</span> <span class="n">kruskals</span> <span class="n">step</span> <span class="n">until</span> <span class="n">k</span> <span class="n">connected</span> <span class="n">components</span>
  <span class="k">return</span><span class="p">:</span> <span class="n">A_k</span><span class="p">,</span> <span class="n">M_k</span></code></pre></figure> <p>This algorithm is known as <strong>Single-Linkage</strong> and is related to a family of <em>hierarchical clustering</em> algorithms. An example of the algorithm running is given below, where the data is separated into three distinct clusters:</p> <figure> <picture> <img src="/assets/img/blog-differentiableclustering/kruskals.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <details><summary>Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="sh">'</span><span class="s">constrained</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
  <span class="n">node_positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)}</span>
  <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
  <span class="n">G</span><span class="p">.</span><span class="nf">add_nodes_from</span><span class="p">(</span><span class="n">node_positions</span><span class="p">)</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="p">.</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">node_positions</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">NODE_COLOR</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">EDGE_COLOR</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">k = 64</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$A_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$M_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">))</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">))</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_aspect</span><span class="p">(</span><span class="sh">'</span><span class="s">equal</span><span class="sh">'</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="sh">'</span><span class="s">box</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Function to update the animation
</span><span class="k">def</span> <span class="nf">update_cluster</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">step</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">clear</span><span class="p">()</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">clear</span><span class="p">()</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">clear</span><span class="p">()</span>

        <span class="n">A</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="nf">solver</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">ncc</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

        <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>

        <span class="n">node_positions</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)}</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_nodes_from</span><span class="p">(</span><span class="n">node_positions</span><span class="p">)</span>

        <span class="c1"># Identify edges based on the adjacency matrix
</span>        <span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N_SAMPLES</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N_SAMPLES</span><span class="p">)</span> <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

        <span class="c1"># Draw the graph
</span>        <span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">node_positions</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">NODE_COLOR</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">edge_color</span><span class="o">=</span><span class="n">EDGE_COLOR</span><span class="p">)</span>


        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$A_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$M_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">fr</span><span class="sh">"</span><span class="s">$k = </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">$</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_aspect</span><span class="p">(</span><span class="sh">'</span><span class="s">equal</span><span class="sh">'</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="sh">'</span><span class="s">box</span><span class="sh">'</span><span class="p">)</span>


<span class="n">frames</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">reversed</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">N_SAMPLES</span><span class="p">)))</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">frames</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span>
<span class="n">animation</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update_cluster</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">frames</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
<span class="n">animation</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">kruskals.gif</span><span class="sh">'</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> </details> <p>In this section we have explored how one can perform a clustering by building spanning forests using Kruskal’s algorithm (Singe Linkage). But how does this get us close to differentiable clustering? To answer this question we need to look at perturbations!</p> <h3 id="perturbations-of-lps">Perturbations of LPs</h3> <p>We will now take a pause from Kruskal’s algorithm to look at <strong>perturbations</strong>, sometimes also called <strong>randomized smoothing</strong>. If maths isn’t your thing, not to worry as understanding the perturbations / smoothing in detail is not neccessary for getting a grasp of the overall methodology. For further reading and a more depth exploration of the subject, I would certainly recommend checking out <a href="https://francisbach.com/integration-by-parts-randomized-smoothing-score-functions/" rel="external nofollow noopener" target="_blank">Francis Bach’s blogpost</a> on the subject!</p> <p>For a <a href="https://en.wikipedia.org/wiki/Convex_hull" rel="external nofollow noopener" target="_blank">convex hull</a> \(\mathcal{C} \subset \mathbb{R}^d\) we define:</p> <ul> <li> <strong>argmax solution</strong> \(y^*:\mathbb{R}^d \rightarrow \mathbb{R}^d\)</li> <li> <strong>max solution</strong> \(F:\mathbb{R}^d\rightarrow\mathbb{R}\)</li> </ul> <p>as follows:</p> \[\DeclareMathOperator{\argmax}{argmax} \begin{align} y^*(\theta) &amp;= \underset{y \in \mathcal{C}}{\argmax} \langle y, \theta \rangle. \\[1em] F(\theta) &amp;= \max\limits_{y \in \mathcal{C}} \langle y, \theta \rangle. \end{align}\] <p>We begin by remarking that for any \(\theta \in \mathbb{R}^d\), \(y^*(\theta)\) will always be one of the extreme points of the convex hull<d-footnote> This follows from the linearity of the inner-product combined with the definition of a convex hull. </d-footnote>. For this reason both \(y^*\) and \(F\) are piece-wise constant in \(\theta\).</p> <p>Hence the gradient \(\nabla_\theta F(\theta) \in \mathbb{R}^d\) and Jacobian \(J_\theta y^*(\theta)\in \mathbb{R}^{d\times d}\) will be zero almost everywhere, similar to the case of classical clustering algorithms.</p> <p>To get differentiability, we would like that as \(\theta\) changes, \(y^*(\theta)\) moves smoothly along the convex hull, instead of jumping from extreme point to extreme point. To do this we will induce a probability distribution by replacing \(\theta\) in the above, by \(\theta + \epsilon Z\), where \(Z\) is some an exponential-family random variable e.g. multi-variate Gaussian with zero mean and identity covariance. This induces a probability distribution:</p> \[\mathbb{P}_Y(Y = y ; \theta) = \mathbb{P}_Z(y^*(\theta + \epsilon Z) = y)\] <p>How can we understand this? Firsly lets fix \(\theta\) and the noise amplitude \(\epsilon &gt; 0\). Provided the noise amplitude is large enough, the argmax solution \(y^*_\epsilon(\theta + \epsilon Z )\) is now a random variable, taking each of the extreme values of the convex hull with a given probability. By taking the expected value, we can obtain a smoothing!</p> <p>This yields the perturbed versions of both the <strong>argmax</strong> and the <strong>max</strong>:</p> \[\DeclareMathOperator{\argmax}{argmax} \begin{align} y^*_\epsilon(\theta) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[\underset{y \in \mathcal{C}}{\argmax} \langle y, \theta + \epsilon \textcolor{orange}{Z} \rangle\right]. \\[1em] F_\epsilon(\theta) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[\max\limits_{y \in \mathcal{C}} \langle y, \theta + \epsilon \textcolor{orange}{Z} \rangle \right]. \end{align}\] <p>We note that as \(\epsilon \rightarrow 0\), both \(F_\epsilon(\theta) \rightarrow F(\theta)\) and \(y^*_\epsilon(\theta) \rightarrow y^*(\theta)\). There are many other properties of the perturbed argmax and max (such as bounding their difference with their unperturbed counterparts), and for further reading we refer the reader to <d-cite key="berthet2020pert"></d-cite>. The figure below depicts the smoothing, (thanks to Quentin Berthet for providing it):</p> <p><img src="/assets/img/blog-differentiableclustering/perturbations_fig.svg" alt="Illustration of smoothing with perturbations." style="display:block; margin-left:auto; margin-right:auto; width:70%;"></p> <h3 id="gradients-of-smoothed-proxies">Gradients of smoothed proxies</h3> <p>When the noise distribution is of exponential family, both the gradient of the perturbed max \(\nabla_\theta F_\epsilon(\theta)\) and the Jacobian of the perturbed argmax \(J_\theta y^*_\theta(\theta)\) can be expressed as both an expectation of a function of the <strong>max</strong> \(F\) and as an expectation of a function of the <strong>argmax</strong> \(y^*\). The details are expressed in the Lemma in the box below:</p> <details><summary>Gradients for Perturbed Proxies <d-cite key="pertgrads"></d-cite>.</summary> <p>For noise distribution \(Z\) with distribution having density \(d\mu(z) = \exp(-\nu(z))dz\) with \(\nu\) twice differentiable:</p> \[\begin{align*} \nabla_\theta F_\epsilon(\theta) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[ y^*(\theta + \epsilon\textcolor{orange}{Z}))\right]\\ &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[ F(\theta + \epsilon \textcolor{orange}{Z})\textcolor{orange}{\nabla_z \nu(Z)} / \epsilon \right]. \\[1.5em] J_\theta y^*_\epsilon(\theta) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[y^*(\theta + \epsilon \textcolor{orange}{Z})\textcolor{orange}{\nabla_z\nu(Z)^T} /\epsilon \right] \\ &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[F(\theta + \epsilon \textcolor{orange}{Z})(\textcolor{orange}{\nabla_z\nu(Z)\nabla_z\nu(Z)^T - \nabla_z^2\nu(Z)}) / \epsilon^2 \right]. \end{align*}\] </details> <p>We note that if we can solve the LP efficiently, then <strong>both of these gradients can be calculated efficiently in parallel</strong> using Monte-Carlo sampling, and hence are suitable for accelerators such as GPUs and TPUs!</p> <h3 id="perturbations-for-clustering">Perturbations for clustering</h3> <p>Lets connect the perturbed proxies we saw above to clustering!</p> <p>It turns out that the maximum weight \(k\)-spanning forest can be in fact written in the LP form, where its adjacency matrix is expressed as an <strong>argmax</strong> and its total weight as a <strong>max</strong>. This makes it compatible for using the perturbations smoothing from the previous section!</p> <p>To see this, let \(\mathcal{C}_k = cvx(\mathcal{A}_k)\) be the convex hull of trees with \(k\) connected components. Then the adjacency matrix of the maximum weight \(k\)-spanning forest takes the form of an argmax:</p> \[\begin{equation} A_k^*(\Sigma) = \underset{A\in \mathcal{C}_k}{\argmax}\left\langle A, \Sigma \right\rangle. \end{equation}\] <p>Its corresponding total weight, take the form of a max:</p> \[\begin{equation} F_k(\Sigma) = \max_{A\in \mathcal{C}_k}\left\langle A, \Sigma \right\rangle. \end{equation}\] <p>Hence applying perturbations to this LP we can obtain differentiable proxies:</p> \[\DeclareMathOperator{\argmax}{argmax} \begin{align} A^*_{k,\epsilon}(\Sigma) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[\underset{A \in \mathcal{C}_k}{\argmax} \langle A, \Sigma + \epsilon \textcolor{orange}{Z} \rangle\right]. \\[1em] F_{k,\epsilon}(\theta) &amp;= \textcolor{orange}{\mathbb{E}_Z}\left[\max\limits_{A \in \mathcal{C}_k} \langle A, \Sigma + \epsilon \textcolor{orange}{Z} \rangle \right]. \end{align}\] <p>The animation below depicts how \(A^*_{k, \epsilon}\) and \(M^*_{k, \epsilon}\) change for varied \(\epsilon &gt; 0\) in the case of \(k=3\).</p> <figure> <picture> <img src="/assets/img/blog-differentiableclustering/pertkruskals.gif" class="img-fluid rounded z-depth-0" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <details><summary>Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">jaxclust</span>
<span class="kn">import</span> <span class="n">jax</span>
<span class="kn">import</span> <span class="n">jax.numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="n">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="nd">@jax.jit</span>
<span class="k">def</span> <span class="nf">pairwise_square_distance</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    euclidean pairwise square distance between data points
    </span><span class="sh">"""</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">G</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">o</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">o</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">g</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">G</span>

<span class="n">solver</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="nf">jit</span><span class="p">(</span><span class="n">jaxclust</span><span class="p">.</span><span class="n">solvers</span><span class="p">.</span><span class="nf">get_flp_solver</span><span class="p">(</span><span class="bp">False</span><span class="p">))</span>
<span class="n">pert_solver</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="nf">jit</span><span class="p">(</span><span class="n">jaxclust</span><span class="p">.</span><span class="n">perturbations</span><span class="p">.</span><span class="nf">make_pert_flp_solver</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">constrained</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

<span class="n">N_SAMPLES</span><span class="o">=</span><span class="mi">32</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">centers</span> <span class="o">=</span> <span class="nf">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_SAMPLES</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">return_centers</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">ids</span><span class="p">]</span>

<span class="n">S</span> <span class="o">=</span> <span class="o">-</span> <span class="nf">pairwise_square_distance</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">S</span> <span class="o">=</span> <span class="p">(</span><span class="n">S</span> <span class="o">-</span> <span class="n">S</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">S</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>

<span class="n">writer</span> <span class="o">=</span> <span class="nc">PillowWriter</span><span class="p">(</span><span class="n">fps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">artist</span><span class="o">=</span><span class="sh">'</span><span class="s">Me</span><span class="sh">'</span><span class="p">),</span> <span class="n">bitrate</span><span class="o">=</span><span class="mi">1800</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="sh">'</span><span class="s">constrained</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sa">rf</span><span class="sh">'</span><span class="s">$\epsilon$ = </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>


<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$A_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$M_{k}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">A_</span><span class="p">,</span> <span class="n">M_</span> <span class="o">=</span> <span class="nf">solver</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">A_</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">M_</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>

<span class="c1"># Function to update the animation
</span><span class="k">def</span> <span class="nf">update_cluster</span><span class="p">(</span><span class="n">epsilon</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">clear</span><span class="p">()</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">clear</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epsilon</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">A</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">A_</span><span class="p">,</span> <span class="n">M_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="nf">pert_solver</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">ncc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">jax</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nc">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$A_{k, \epsilon}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$M_{k, \epsilon}^*(\Sigma)$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sa">rf</span><span class="sh">'</span><span class="s">$\epsilon$ = </span><span class="si">{</span><span class="n">epsilon</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>


<span class="n">frames</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span>  <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">jnp</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">frames</span><span class="p">,</span> <span class="n">jnp</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">animation</span> <span class="o">=</span> <span class="nc">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update_cluster</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">frames</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
<span class="n">animation</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">pertkruskals.gif</span><span class="sh">'</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> </details> <p>So at this point we have a clustering method which:</p> <ul> <li>Is <strong>differentiable</strong>!</li> <li>Whose gradients can be computed as a Monte Carlo estimator <strong>in parallel</strong>.</li> <li>Compatible with accelerators and autodiff (since all operatiors are matmal).</li> </ul> <p>Lets look at one potential application (among many).</p> <h3 id="incorporating-partial-information">Incorporating Partial Information</h3> <p>Suppose we have data where some (or all) of the points have labels i.e. a semi-supervised learning or fully-supervised learning setting. We would ideally like to learn representations of our data, which when clustered, respect this label information.</p> <p>To illustrate this point, lets consider the simple example below, where the embeddings of a batch of data are depicted by the circles. Lets suppose that the two red points share the same label e.g. <em>cat</em> which is different from that of the blue point e.g. <em>dog</em>, whilst all other points are unlabelled.</p> <p><img src="/assets/img/blog-differentiableclustering/constraints.svg" alt="Partial label Information can be encoded via must links and must-not links." style="display:block; margin-left:auto; margin-right:auto; width:70%;"></p> <p>If we were to cluster these embeddings into two clusters, using our approach described above, we would obtain something like the depiction below:</p> <p><img src="/assets/img/blog-differentiableclustering/unconstrained.svg" alt="test" style="display:block; margin-left:auto; margin-right:auto; width:70%;"></p> <p>However, this is clustering is inconsistent with the label information, since the blue point is now in the same cluster as the two red points.</p> <p>To enforce label consistency, we can encode all the label information into a \(n\times n\) constraint matrix \(M_\Omega\) (depicted above), whose \((i, j)^{th}\) entry is:</p> <ul> <li>\(1\) if both \(i\) and \(j\) should be in the same connected component i.e. a <strong>must-link constraint</strong>.</li> <li>\(0\) if \(i\) and \(j\) should not be in the same connencted component i.e. a <strong>must-not link constraint</strong>.</li> <li>\(\star\), a special value signifing there are no constraints between \(i\) and \(j\).</li> </ul> <p>Note the <strong>must-link</strong> and <strong>must-not-link</strong> constraints are very general concepts, and go beyond label information. For example, such constraints can ecompass active learning, self-supervised learning and fairness conditions.</p> <p>For any constraint matrix \(M_\Omega\), we can also consider modified versions of the maximum weight \(k\)-spanning forest LP, restricted to the set of forests that respect the constraint matrix \(\mathcal{C}_k(M_\Omega)\):</p> \[\begin{equation} A_k^*(\Sigma ; M_\Omega) = \underset{A\in \mathcal{C}_k(M_\Omega)}{\argmax}\left\langle A, \Sigma \right\rangle. \end{equation}\] \[\begin{equation} F_k(\Sigma ; M_\Omega) = \max_{A\in \mathcal{C}_k(M_\Omega)}\left\langle A, \Sigma \right\rangle. \end{equation}\] <p>Unfortunately, the above LP has a matroid structure only in certain settings, so running Kruskal’s algorithm but adding checks for <strong>must-not-link</strong> constraints and enforcing <strong>must-link</strong> constraints will not guarentee optimality. It is however, a suitable heurestic that we can still use to obtain clusters satisfying our constraint matrix \(M_\Omega\). For details on how to implement the constained clustering, see the source code of <a href="https://lawrencemmstewart.github.io/jaxclust/" rel="external nofollow noopener" target="_blank">JaxClust</a>.</p> <p>Solving the LP with constrained clustering would result in the clusters displayed below:</p> <p><img src="/assets/img/blog-differentiableclustering/constrained.svg" alt="test" style="display:block; margin-left:auto; margin-right:auto; width:70%;"></p> <h3 id="a-loss-function-for-differentiable-clustering">A Loss Function for Differentiable Clustering</h3> <p>Since \(\mathcal{C}_k(M_\Omega) \subseteq \mathcal{C}\), it trivially follows that \(F_k(\Sigma ; M_\Omega) \leq F_k(\Sigma )\). In words, the total weight of the maximum \(k\)-spanning forest will always be greater than or equal to the total weight of the maximum \(k\)-spanning forest satisfying the constraint matrix \(M_\Omega\), simply as there are more forests to choose from!</p> <p>We can design a loss function:</p> \[\ell(\Sigma ; M_\Omega) = F_k(\Sigma) - F_k(\Sigma ; M_\Omega).\] <p>The above loss function is non-negative, and is zero if and only if the clustering with the constraint matrix \(M_\Omega\) leads to a forest having the same weight as with no constraints. We can think of this as <em>“the loss will be zero if the embeddings are in a position that satisfies the label constraints”.</em></p> <p>Furhermore, by replacing \(F_k\) with \(F_{k, \epsilon}\), this loss function can be smoothed as we have previously seen:</p> \[\ell_\epsilon(\Sigma ; M_\Omega) = F_{k,\epsilon}(\Sigma) - F_{k, \epsilon}(\Sigma ; M_\Omega).\] <p>We remark that the gradient of the loss function can be trivially calculated as:</p> \[\nabla_\Sigma \ell_\epsilon(\Sigma ; M_\Omega) = A_{k,\epsilon}(\Sigma) - A_{k, \epsilon}(\Sigma ; M_\Omega).\] <p>Hence the gradient the \(\ell_\epsilon\) corresponds to the difference of the adjacency matrix of the constrained and unconstrained spanning forest.</p> <p>We refer to this loss as the <strong>Partial-Fenchel Young loss</strong>, which turns out to have many desirable statistical properties. The loss can also be expressed as an infinium loss (a.k.a partial loss) over a Fenchel-Young objective <d-cite key="fy"></d-cite>, hence its nomenclature. For more information on the properties and forms of this loss, please refer to the paper <d-cite key="stewart2023differentiable"></d-cite>.</p> <h3 id="semi-supervised-learning-pipeline">Semi-Supervised Learning Pipeline</h3> <p>An example pipeline to learn embeddings from partial information is depicted below.</p> <p><img src="/assets/img/blog-differentiableclustering/pipeline.svg" alt="" style="display:block; margin-left:auto; margin-right:auto; width:100%;"></p> <p>Embeddings \(V\) are generated from data \(X\) using a model (e.g. a neural network), parameterized by weights \(w\). From these embeddings one can construct a similarity matrix \(\Sigma\) and calculate the Partial FY loss using any label constraints available for the batch. The model weights are updated in the backwards pass, informed by the gradients previously discussed above.</p> <p>This methodology can lead to embeddings that are clusterable, and suitable for down-stream transfer learning via a linear probe. For experiments using this pipeline, please refer to our <a href="https://openreview.net/pdf?id=nRfcVBsF9n" rel="external nofollow noopener" target="_blank">paper</a>!</p> <h3 id="class-discovery">Class Discovery</h3> <p>It turns out our clustering methodology allows a neural network to learn meaningful representations from partial label information even in the difficult situation where some classes are unaccounted for.</p> <p>Below is a tSNE visualization of embeddings for a small CNN (LeNET) trained on the MNIST data set with all but 100 labels have been withheld, and where three of the ten classes have <strong>no labels present in the train set</strong> (depicted in bold).</p> <p>Despite never seeing a label for these three classes, the model has leveraged partial label information through clustering to infer these classes. Investigating potential applications of learning through clustering to zero-shot and self-supervised learning are promising avenues for future work.</p> <p><img src="/assets/img/blog-differentiableclustering/tsne.svg" alt="" style="display:block; margin-left:auto; margin-right:auto; width:50%;"></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"LawrenceMMStewart/LawrenceMMStewart.github.io","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Lawrence Stewart. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>